{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#please: pip install -r requirements.txt before running\n","#if this import still fails saying module not found _lzma please uninstall python 3.10.8 from pyenv, run: brew install xz, reinstall python version 3.10.8\n","#note: the above error is not found with conda installations of python, only pyenv has this problem\n","\n","import torchvision"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["%%capture\n","\n","import os\n","import json\n","import random\n","import shutil\n","import pybboxes as pbx\n","\n","import torch\n","from IPython.display import Image, clear_output"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1670322299719,"user":{"displayName":"BISHAKH DUTTA","userId":"13448161197216856725"},"user_tz":-330},"id":"QouhoqSDRoWa"},"outputs":[],"source":["#helper functions to handle data\n","\n","def getFile(root_path):\n","    file_list = list()\n","    for file in os.listdir(root_path):\n","        if ('.' in file) == False and file != \"coco\":\n","            file_list.append(file)\n","    return file_list\n","\n","\n","def getAllJson(path):\n","    file_list = list()\n","    for file in os.listdir(path):\n","        if file.split('.')[1] != \"vott\":\n","            file_list.append(path + '/' + file)\n","    return file_list\n","\n","\n","def read_json(path: str):\n","    with open(path, 'r') as f:\n","        data = json.load(f)\n","    return data\n","\n","\n","def getImg(path):\n","    img_list = list()\n","    for img_file in os.listdir(path):\n","        if img_file != \"annotations\":\n","            img_list.append(img_file)\n","    return img_list"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":924,"status":"ok","timestamp":1670322306359,"user":{"displayName":"BISHAKH DUTTA","userId":"13448161197216856725"},"user_tz":-330},"id":"TsW2rQfrR6Ps"},"outputs":[],"source":["#function to convert the original kaggle dataset to coco format\n","\n","def convert2coco(root_path,coco_path,split_rate=0.1):\n","    os.makedirs(coco_path + \"annotations/\")\n","    os.makedirs(coco_path + \"train/\")\n","    os.makedirs(coco_path + \"val/\")\n","    \n","    all_class_file = getFile(root_path) \n","    coco_train_annotations = dict(images=list(), annotations=list(), categories=list())  \n","    coco_val_annotations = dict(images=list(), annotations=list(), categories=list())  \n","    coco_annotations = [coco_train_annotations, coco_val_annotations]  \n","    img_idx = 0\n","    bbox_idx = 0\n","    label_idx = 0\n","    \n","    \n","    for idx, label in enumerate(all_class_file):\n","        category = dict(id=idx, supercategory=\"Arthropod\", name=label)\n","        coco_annotations[0][\"categories\"].append(category)\n","        coco_annotations[1][\"categories\"].append(category)\n","\n","    for each_class in all_class_file:\n","        print(\"start to convert \"+each_class+'\\n')\n","        root_img = root_path + each_class + '/' \n","        all_annotations = getAllJson(root_path + each_class + \"/annotations\")  \n","        for json_file in all_annotations: \n","            data = read_json(json_file)\n","            flag = 1 if random.random() < split_rate else 0  \n","            shutil.copyfile(root_img + data[\"asset\"][\"name\"],\n","                        coco_path + (\"train/\" if flag == 0 else \"val/\") + data[\"asset\"][\"name\"])\n","        \n","            img = dict(file_name=data[\"asset\"][\"name\"],\n","                       height=data[\"asset\"][\"size\"][\"height\"],\n","                       width=data[\"asset\"][\"size\"][\"width\"],\n","                       id=img_idx)\n","            coco_annotations[flag][\"images\"].append(img)\n","\n","            for region in data[\"regions\"]:\n","                bbox = region[\"boundingBox\"]\n","                anno = dict(image_id=img_idx, segmentation=[[]], area=240, iscrowd=0,\n","                            bbox=[bbox[\"left\"], bbox[\"top\"], bbox[\"width\"], bbox[\"height\"]],\n","                            id=bbox_idx, category_id=label_idx)\n","                bbox_idx += 1\n","                coco_annotations[flag][\"annotations\"].append(anno)\n","\n","            img_idx += 1\n","        label_idx += 1\n","\n","    with open(coco_path+\"annotations/train.json\", \"w\") as f:\n","        json.dump(coco_annotations[0], f)\n","    with open(coco_path + \"annotations/val.json\", \"w\") as f:\n","        json.dump(coco_annotations[1], f)\n","    print(\"finish...\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %%capture\n","# #Uncomment and run this cell to set up Kaggle API token, download the dataset, unzip it and convert it into coco format(only if coco.zip is not downloaded)\n","\n","\n","# !mkdir ~/.kaggle\n","# !touch kaggle.json\n","# api_token = {\"username\":\"bishakhdutta\",\"key\":\"bb5c64ace271719d673b785e520d4fa8\"}\n","\n","# with open('kaggle.json', 'w') as file:\n","#     json.dump(api_token, file)\n","\n","# !mv kaggle.json ~/.kaggle/kaggle.json\n","# !chmod 600 ~/.kaggle/kaggle.json\n","\n","\n","# !kaggle datasets download -d mistag/arthropod-taxonomy-orders-object-detection-dataset\n","# !unzip arthropod-taxonomy-orders-object-detection-dataset.zip\n","\n","\n","# !mkdir(\"coco/\")\n","# convert2coco(\"ArTaxOr/\",\"coco/\",0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %%capture\n","# #Uncomment and run this cell to unzip the coco.zip file downloaded from drive(only if already not unzipped manually)\n","\n","\n","# !unzip coco.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KYZ75Wck9-g3"},"outputs":[],"source":["json_file = \"coco/annotations/train.json\"\n","with open(json_file) as datafile:\n","  data_train = json.load(datafile)\n","\n","json_file = \"coco/annotations/val.json\"\n","with open(json_file) as datafile:\n","  data_val= json.load(datafile)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#verify whether converted into coco properly\n","\n","print(data_train['images'][0])\n","print(data_train['categories'][0])\n","print(data_train['annotations'][0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#verify num_classes = 7 or else class names will be just numbers\n","\n","num_classes = len(data_train['categories'])\n","print(num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(data_train['images']))\n","print(len(data_val['images']))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#makes folders for storing data in yolo(darknet) format\n","\n","!mkdir data\n","!mkdir data/labels\n","!mkdir data/labels/train data/labels/val"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#function to convert the coco data into yolo(darknet) format\n","\n","def coco2yolo(json_file_path, yolo_annotations_path):\n","    \n","    with open(json_file_path) as datafile:\n","        data = json.load(datafile)\n","\n","    for image in data[\"images\"]:\n","        image_name = image['file_name'].split(\".\")[0]\n","        txt_file_path = os.path.join(yolo_annotations_path, image_name+\".txt\")\n","        image_list = []\n","        for annotation in data['annotations']:\n","            if annotation['image_id'] == image['id']:\n","                size = [image['width'], image['height']]\n","                yolobbox = pbx.convert_bbox(annotation['bbox'], from_type=\"coco\", to_type=\"yolo\", image_size=size)\n","                category = annotation['category_id']\n","                image_list.append((category, yolobbox))\n","        input = []\n","        for output in image_list:\n","            string_line = \"{} {} {} {} {}\".format(output[0], output[1][0], output[1][1], output[1][2], output[1][3])\n","            input.append(string_line)\n","        with open(txt_file_path, 'w') as fp:\n","            for line in input:\n","                fp.write(line)\n","                fp.write('\\n')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#convert coco to yolo(darknet)\n","\n","coco2yolo('coco/annotations/train.json','data/labels/train/')\n","coco2yolo('coco/annotations/val.json','data/labels/val/')\n","\n","shutil.move('coco/images','data')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["'coco/images'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["shutil.move('data/images','coco')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#make sure git is installed and .gitconfig file is set up to clone the yolov5 repo\n","\n","!git clone https://github.com/ultralytics/yolov5 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cd yolov5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%capture\n","pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#line magic function that creates and writes into files\n","\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#make sure there are 7 classes or else names of classes will be just numbers\n","\n","classes = ['Coleoptera','Diptera','Hymenoptera','Hemiptera','Lepidoptera','Araneae','Odonata']\n","if(num_classes!=7):\n","    classes = list(range(num_classes))\n","    classes = [str(x) for x in classes]\n","print(classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%writetemplate data/data_config.yaml\n","\n","train: ../data/images/train/\n","val: ../data/images/val/\n","\n","nc: {num_classes}\n","\n","names: {classes}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cat models/yolov5n.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%writetemplate models/model_config.yaml\n","# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license\n","\n","# Parameters\n","nc: {num_classes} # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.25  # layer channel multiple\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 v6.0 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, C3, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 6, C3, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, C3, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 3, C3, [1024]],\n","   [-1, 1, SPPF, [1024, 5]],  # 9\n","  ]\n","\n","# YOLOv5 v6.0 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, C3, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","#trains the model on our dataset, adjust batch size and epoch based on available hardware\n","\n","!python train.py --batch 8 --epochs 100 --data data/data_config.yaml --cfg models/model_config.yaml --weights '' --project 'results' --name 'custom_yolov5s_results' "]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPZoIZZeu2+O0KNXJ9gxp1J","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.8 ('.venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"9696ea4a5fcb39fceda38075ecd64aec815c00e5b48dff47682660a43898ac37"}}},"nbformat":4,"nbformat_minor":0}
